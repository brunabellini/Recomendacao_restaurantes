{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Blibiotecas"
      ],
      "metadata": {
        "id": "eSInHrbqMmNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "id": "UR1uMHvvFkjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxOh9YklFiaU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from serpapi import GoogleSearch\n",
        "import ast\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recolhendo dados principais dos estabelecimentos\n",
        "O primeiro tipo de dados que vamos obter são as infromações básicas dos restaurantes, como: localização, nota média, faixa de preço, categoria, entre outros.\n",
        "<br>\n",
        "Algumas etapas são necessaŕias para alcançar nosso objetivo:\n",
        "\n",
        "\n",
        "1.   Definir quais termos iremos passar como requisição na API para realizar pesquisas no Google Maps\n",
        "2.   Realizar as requisições e armazenar os resultados\n",
        "3. Passar os dados obtidos para Pandas DataFrame e aplicar as transformações necessaŕias a fim de facilitar o manuseio deles no decorrer do projeto\n",
        "4. Armazenar os dados\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mxoUl0INQDLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções"
      ],
      "metadata": {
        "id": "H0N2yGfIORE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_na_api(pesquisas, key):\n",
        "\n",
        "  '''\n",
        "  Recebe a lista dos termos a serem pesquisados no Google Maps juntamente com a chave individual que possibilita que a requsição seja feita.\n",
        "  Retorna lista de listas com json dos resultados obtidos, requisições que falharam e todas as pesquisas realizadas.\n",
        "\n",
        "  pesquisas = Termos a ser pesquisado\n",
        "  key = Chave individual da API\n",
        "  '''\n",
        "  local_results = []\n",
        "  local_fail = []\n",
        "  local_titles = []\n",
        "\n",
        "  for pesquisa in pesquisas:\n",
        "    print(pesquisa)\n",
        "    for pg in range(0, 101, 20):\n",
        "      params = {\n",
        "        \"engine\": \"google_maps\",\n",
        "        \"q\": pesquisa,\n",
        "        \"type\": \"search\",\n",
        "        \"api_key\": key,\n",
        "        \"start\":pg,\n",
        "        \"ll\": '@-23.5489,-46.6388,7z'\n",
        "      }\n",
        "\n",
        "      search = GoogleSearch(params)\n",
        "      results = search.get_dict()\n",
        "      try:\n",
        "        local_results = (local_results + results[\"local_results\"])\n",
        "        local_titles.append(pesquisa)\n",
        "      except:\n",
        "        print('fail')\n",
        "        if results['error'] == 'Your searches for the month are exhausted. You can upgrade plans on SerpApi.com website.':\n",
        "          print(f'O último erro foi:\\n{results}')\n",
        "          return [local_results, local_fail, local_titles]\n",
        "        else:\n",
        "          local_titles.append(pesquisa)\n",
        "          local_fail.append(pesquisa)\n",
        "          break\n",
        "\n",
        "\n",
        "  return [local_results, local_fail, local_titles]\n",
        "\n",
        "def criando_pesquisas(locais_pesquisas, regioes_sp):\n",
        "  '''\n",
        "  Recebe e combina strings para retornar diversas variações de pesquisa\n",
        "  locais_pesquisas = categorias pesquisadas\n",
        "  regioes_sp = localização a ser pesquisada\n",
        "  '''\n",
        "  lista_pesquisas = []\n",
        "\n",
        "  for l in locais_pesquisas:\n",
        "    for r in regioes_sp:\n",
        "      lista_pesquisas.append(l+r)\n",
        "  \n",
        "  return lista_pesquisas"
      ],
      "metadata": {
        "id": "oKQpfWsHT8Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo Pesquisas"
      ],
      "metadata": {
        "id": "SCBAxnflOVkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_results = []\n",
        "\n",
        "locais_pesquisas = [\n",
        "    \"Churrascaria\",\n",
        "    \"Almoço\",\n",
        "    \"Jantar Romântico\",\n",
        "    \"Jantar\",\n",
        "    \"Dogão\",\n",
        "    \"Cachorro quente\",\n",
        "    \"Lanche\",\n",
        "    \"Sanduiche\",\n",
        "    \"Prato Feito\",\n",
        "    \"PF\",\n",
        "    \"Sorveteria\",\n",
        "    \"Balada\",\n",
        "    \"Bolos\",\n",
        "    \"Rodízio de Massas\",\n",
        "    \"Rodízio de Doces\",\n",
        "    \"Rodízio de Pizza\",\n",
        "    \"Self-Service\",\n",
        "    \"Comida de Boteco\",\n",
        "    \"Restuarante com Vista\",\n",
        "    \"Comida Mineira\",\n",
        "    \"Feijoada\",\n",
        "    \"Salada\",\n",
        "    \"Comida Saudavel\",\n",
        "    \"Marmita\",\n",
        "    \"Balada Alternativa\",\n",
        "    \"Restaurante Diferente\",\n",
        "    \"Doceria Gourmet\",\n",
        "    \"Petiscos\",\n",
        "    \"Brunch\",\n",
        "    \"Galeteria\",\n",
        "    \"Doce Francês\",\n",
        "    \"Doce Árabe\",\n",
        "    \"Restaurante de Comida Chinesa\",\n",
        "    \"Restaurante Alternativo\",\n",
        "    \"Café Alternativo\",\n",
        "    \"Rodízio de Drinks\",\n",
        "     \"Comida do Norte\",\n",
        "    \"Café em São Paulo\",\n",
        "    \"Restaurante em São Paulo\",\n",
        "    \"Pizzaria em São Paulo\",\n",
        "    \"Pizzaria Napolitana em São Paulo\",\n",
        "    \"Hamburgueria em São Paulo\",\n",
        "    \"Rodízio de Carne em São Paulo\",\n",
        "    \"Rodízio de Comida Japones em São Paulo\",\n",
        "    \"Rodízio em São Paulo\",\n",
        "    \"Bar em São Paulo\",\n",
        "    \"Barzinho em São Paulo\",\n",
        "    \"Pub em São Paulo\",\n",
        "    \"Trattoria em São Paulo\",\n",
        "    \"Padaria em São Paulo\",\n",
        "    \"Doceria em São Paulo\",\n",
        "    \"Boteco em São Paulo\",\n",
        "    \"Balada em São Paulo\",\n",
        "    \"Restaurante Italiano em São Paulo\",\n",
        "    \"Restaurante Japonês em São Paulo\",\n",
        "    \"Restaurante Chinês em São Paulo\",\n",
        "    \"Restaurante Mediterrâneo em São Paulo\",\n",
        "    \"Restaurante Árabe em São Paulo\",\n",
        "    \"Restaurante Nordestino em São Paulo\",\n",
        "    \"Restaurante Alemão em São Paulo\",\n",
        "    \"Restaurante Tailandês\",\n",
        "    \"Restaurante de Comida Australiana\",\n",
        "    \"Restaurante de Comida Coreana\",\n",
        "    \"Restaurante de Comida Indiana\",\n",
        "    \"Churrascaria Argentina\",\n",
        "    \"Churrascaria Gaúcha\"\n",
        "]\n",
        "\n",
        "regioes_sp = [\"\", \" em São Paulo Zona Norte\", \" em São Paulo Zona Sul\", \" em São Paulo\", \" Barato\", \" Caro\"]\n",
        "\n",
        "pesquisas = criando_pesquisas(locais_pesquisas, regioes_sp)"
      ],
      "metadata": {
        "id": "FhfMI5iwOKQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizando Requisições"
      ],
      "metadata": {
        "id": "OZwNmhpyOZHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = '29c08d9dcd009ac3c8fe92404122edd4f29225ae6fd19b8163b705629aa1b7f5' # O limite de consultas foi esgotado\n",
        "local_results = buscar_na_api(pesquisas, key)"
      ],
      "metadata": {
        "id": "a92V3j4xFoLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratando dados"
      ],
      "metadata": {
        "id": "edM9PjawO1Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset principal\n",
        "\n",
        "overview = pd.DataFrame(local_results[0])\n",
        "\n",
        "# dividindo dados de latitude e longitude em colunas distintas\n",
        "gps_coordinates = pd.concat([pd.DataFrame([coo]) for coo in overview['gps_coordinates']]).reset_index()\n",
        "overview = pd.concat([overview, gps_coordinates], axis=1)\n",
        "\n",
        "# definindo colunas que irão compor o dataset\n",
        "df_overview = overview[['position', 'title', 'place_id', 'data_id', 'data_cid', 'rating',\n",
        "       'reviews', 'price', 'type', 'address', 'latitude', 'longitude', 'open_state',\n",
        "       'description', 'thumbnail']]"
      ],
      "metadata": {
        "id": "HO_dUzIBF8eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset horarios de funcionamento\n",
        "\n",
        "# dispondo dias e seus horarios de funcionamento em colunas distintas\n",
        "titles = overview[['title',\t'place_id']]\n",
        "operating_hours = pd.concat([pd.DataFrame([oph]) for oph in overview['operating_hours']]).reset_index()\n",
        "df_operating_hours = pd.concat([titles, operating_hours], axis=1)\n",
        "\n",
        "# definindo colunas que irão compor o dataset\n",
        "df_operating_hours =  df_operating_hours[['title', 'place_id',  'sunday',    'monday', 'tuesday', 'wednesday', 'thursday',  'friday',  'saturday']]"
      ],
      "metadata": {
        "id": "UNTV_rPvGEgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset de opções de serviço\n",
        "\n",
        "# dispondo colunas de opção de serviço em colunas distintas\n",
        "service_options = pd.concat([pd.DataFrame([so]) for so in overview['service_options']]).reset_index()\n",
        "df_service_options = pd.concat([titles, service_options], axis=1)\n",
        "\n",
        "# definindo colunas que irão compor o dataset\n",
        "df_service_options = df_service_options[['title', 'place_id','index','dine_in','takeout','delivery',\n",
        "           'curbside_pickup', 'no_contact_delivery','drive_through','takeaway','kerbside_pickup',\n",
        "           'in_store_shopping','in_store_pickup'\n",
        "           ]]"
      ],
      "metadata": {
        "id": "vP6bbrqoGIsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvando Dados"
      ],
      "metadata": {
        "id": "rCcP1t9_P1ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_overview = df_overview.drop_duplicates()\n",
        "df_overview.to_csv(f'df_overview (1).csv', index=False)\n",
        "\n",
        "df_operating_hours = df_operating_hours.drop_duplicates()\n",
        "df_operating_hours.to_csv(f'df_operating_hours (1).csv', index=False)\n",
        "\n",
        "df_service_options = df_service_options.drop_duplicates()\n",
        "df_service_options.to_csv(f'df_service_options (1).csv', index=False)"
      ],
      "metadata": {
        "id": "YlyT3pizGKnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recolhendo dados de Review\n",
        "Os dados de Review trazem infromações mais de talhadas dos estabelecimentos, como comentários, avaliações, horários de movimento, entre outros.<br> Diferente das informações básicas recolhidas anteriormente, nem todos os estabelcimentos terão esse tipo de dado.\n",
        "<br>\n",
        "Algumas etapas são necessaŕias para alcançar nosso objetivo:\n",
        "\n",
        "\n",
        "1.   Definir quais estabelecimentos serão usados na consulta dentre os presentes nos Dados Gerais. \n",
        "> *Não é possível de recolher de todos. Isso porque temos uma limitação de infraestrutura referente ao limite de requisições permitidas por usuário na API. <br>\n",
        "Para ilustrar, caso quisessemos pegar os dados de review dos mais de 8 mil restaurantes presentes nos Dados Gerais, precisariamos de mais de 80 Chaves individuais, o que seria inviável. <br>\n",
        "Outra alternativa seria utilizar a versão paga da API, porém, levando em conta o tipo e finalidade deste projeto, também não se mostra viável.*\n",
        "\n",
        "\n",
        "2.   Realizar as requisições e armazenar os resultados\n",
        "3. Passar os dados obtidos para Pandas DataFrame e aplicar as transformações necessaŕias a fim de facilitar o manuseio deles no decorrer do projeto\n",
        "4. Armazenar os dados"
      ],
      "metadata": {
        "id": "4_MHy1qe-5XU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções"
      ],
      "metadata": {
        "id": "OLdGtUaIRWDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_review_info(params):\n",
        "  c = 0\n",
        "  search = GoogleSearch(params)\n",
        "  results = search.get_dict()\n",
        "  print(results)\n",
        "  try:\n",
        "    place_results = results[\"place_results\"]\n",
        "    return place_results\n",
        "  except:\n",
        "    print('fail')"
      ],
      "metadata": {
        "id": "Am2HSfl9CZhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def back_to_json(txt, chave1, chave2=None):\n",
        "  new_txt = txt\n",
        "  # new_txt = re.sub('\"', 'aspas', txt)\n",
        "  new_txt = re.sub('\\'', '\"', new_txt)\n",
        "  # new_txt = re.sub('aspas', '\\'', new_txt)\n",
        "  if chave2 == None:\n",
        "    return ast.literal_eval(new_txt)[chave1]\n",
        "  else:\n",
        "    return ast.literal_eval(new_txt)[chave1][chave2]"
      ],
      "metadata": {
        "id": "vG_TvFXvCi3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo Restaurantes"
      ],
      "metadata": {
        "id": "zZPm_7UOSCiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Devido à limitação de infraestrutura da API apresentar um pequeno limite de requisições por usário, só pudemos recolher informações de review de uma amostra dos nossos dados.\n",
        "place_id_list = df_overview.sample(600)\n",
        "place_id_list = list(place_id_list.place_id.values)"
      ],
      "metadata": {
        "id": "L-gTcIUsCc79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizando Requisições"
      ],
      "metadata": {
        "id": "3PSiCs7NR_C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "place_results_list = []\n",
        "\n",
        "for p in place_id_list:\n",
        "    print(p)\n",
        "    params = {\n",
        "      \"engine\": \"google_maps\",\n",
        "      \"type\": \"place\",\n",
        "      \"place_id\": p,\n",
        "      \"api_key\": key\n",
        "    }\n",
        "    place_results_list.append(get_review_info(params))\n",
        "\n",
        "df_review_total = pd.DataFrame(place_results_list)"
      ],
      "metadata": {
        "id": "yukRjYMCFpNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratando Dados"
      ],
      "metadata": {
        "id": "LKt20HuBS-b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overview_avaliacoes_list = []\n",
        "most_relevant_reviews_list = []\n",
        "tambem_procuram_list = []\n",
        "horarios_movimento_list = [] \n",
        "\n",
        "for index, row in  df_review_total.iterrows():\n",
        "\n",
        "  # tabela do overview das avaliacoes\n",
        "  try:\n",
        "    overview_avaliacoes = pd.DataFrame({\n",
        "        'title': row['title'], \n",
        "        'place_id': row['place_id'], \n",
        "        'user_reviews(summary)': row['user_reviews']['summary'], \n",
        "        'time_spent': row['popular_times']['live_hash']['time_spent']\n",
        "        })\n",
        "    overview_avaliacoes_list.append(overview_avaliacoes)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "  # tabela de reviews mais relevantes\n",
        "  try:\n",
        "    most_relevant_reviews = pd.DataFrame(row['user_reviews']['most_relevant'])\n",
        "    most_relevant_reviews['title'] = row['title']\n",
        "    most_relevant_reviews['place_id'] = row['place_id']\n",
        "    most_relevant_reviews_list.append(most_relevant_reviews)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  # tabela de correlação entre os restaurantes\n",
        "  try:\n",
        "    tambem_procuram = pd.DataFrame(row['people_also_search_for'][0]['local_results'])\n",
        "    tambem_procuram['estabelecimento_referencia'] = row['title']\n",
        "    gps_coordinates = pd.concat([pd.DataFrame([coo]) for coo in tambem_procuram['gps_coordinates']]).reset_index()\n",
        "    tambem_procuram = pd.concat([tambem_procuram, gps_coordinates], axis=1)\n",
        "\n",
        "\n",
        "    tambem_procuram_list.append(tambem_procuram)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "  # tabela de grafico de horáros\n",
        "  try:\n",
        "    horarios_movimento = pd.DataFrame(row['popular_times']['graph_results'])\n",
        "    horarios_movimento['title'] = row['title']\n",
        "    horarios_movimento_list.append(horarios_movimento)\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "ZaaicOCWCj00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvando Dados"
      ],
      "metadata": {
        "id": "v56Hpkn2TNSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overview_avaliacoes = pd.concat(overview_avaliacoes_list)\n",
        "overview_avaliacoes = overview_avaliacoes.astype(str).drop_duplicates()\n",
        "overview_avaliacoes.to_csv('overview_avaliacoes.csv', index=False)\n",
        "\n",
        "most_relevant_reviews = pd.concat(most_relevant_reviews_list)\n",
        "most_relevant_reviews = most_relevant_reviews[['title', 'place_id', 'username', 'rating', 'description', 'images', 'date']]\n",
        "most_relevant_reviews = most_relevant_reviews.astype(str).drop_duplicates()\n",
        "most_relevant_reviews.to_csv('most_relevant_reviews.csv', index=False)\n",
        "\n",
        "tambem_procuram = pd.concat(tambem_procuram_list)\n",
        "tambem_procuram = tambem_procuram[['estabelecimento_referencia', 'position', 'title', 'rating',\n",
        "      'reviews', 'type', 'thumbnail', 'latitude', 'longitude',]]\n",
        "tambem_procuram = tambem_procuram.astype(str).drop_duplicates()\n",
        "tambem_procuram.to_csv('tambem_procuram.csv', index=False)\n",
        "\n",
        "horarios_movimento = pd.concat(horarios_movimento_list)\n",
        "horarios_movimento = horarios_movimento.astype(str).drop_duplicates()\n",
        "horarios_movimento.to_csv('horarios_movimento.csv', index=False)"
      ],
      "metadata": {
        "id": "_P-X1fAkClFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}